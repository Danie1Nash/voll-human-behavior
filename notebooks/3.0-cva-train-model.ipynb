{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from math import ceil\n",
    "from torch.utils.data.dataset import random_split\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "from torchsummary import summary\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ignite import *\n",
    "from ignite.metrics import Accuracy, Precision, Recall, Fbeta, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 12, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(12, 36, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(26244+48, 120)\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        self.fc3 = nn.Linear(60, num_classes)\n",
    "        \n",
    "    def forward(self, input1, input2):\n",
    "        out1 = self.layer1(input1)\n",
    "        out1 = self.layer2(out1)\n",
    "        out1 = self.layer3(out1)\n",
    "        out1 = out1.reshape(out1.size(0), -1)\n",
    "        out1 = self.drop_out(out1)\n",
    "\n",
    "        out2 = self.layer1(input2)\n",
    "        out2 = self.layer2(out2)\n",
    "#         out2 = self.layer3(out2)\n",
    "        \n",
    "        out2 = out2.reshape(out2.size(0), -1)\n",
    "        out2 = self.drop_out(out2)\n",
    "\n",
    "        out = torch.cat((out1.view(out1.size(0), -1), out2.view(out2.size(0), -1)), dim=1)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestModelCallback:\n",
    "    # metric - metric to monitor\n",
    "    # mode - min or max\n",
    "    def __init__(self, model, metric, mode, path):\n",
    "        self.metric = metric\n",
    "\n",
    "        if mode not in [\"min\", \"max\"]:\n",
    "            raise Exception(\"mode should be one max or min\")\n",
    "\n",
    "        self.mode = mode\n",
    "        if self.mode == \"min\":\n",
    "            self.best = float('Inf')\n",
    "        else:\n",
    "            self.best = -float('Inf')\n",
    "\n",
    "        self.model = model\n",
    "        self.path = path\n",
    "\n",
    "    def save_best(self, scores):\n",
    "        if self.mode == \"min\":\n",
    "            if scores[self.metric] < self.best:\n",
    "                self.best = scores[self.metric]\n",
    "                # torch.save(self.model.state_dict(), self.path)\n",
    "\n",
    "                print(f\"New Model has been saved: {self.metric} = {self.best}\")\n",
    "        else:\n",
    "            if scores[self.metric] > self.best:\n",
    "                self.best = scores[self.metric]\n",
    "                # torch.save(self.model.state_dict(), self.path)\n",
    "\n",
    "                print(f\"New Model has been saved: {self.metric} = {self.best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsGroup:\n",
    "    def __init__(self, metrics_dict):\n",
    "        self.metrics = metrics_dict\n",
    "\n",
    "    def update(self, output):\n",
    "        for name, metric in self.metrics.items():\n",
    "            metric.update(output)\n",
    "\n",
    "    def compute(self):\n",
    "        output = {}\n",
    "        for name, metric in self.metrics.items():\n",
    "            output[name] = metric.compute()\n",
    "        return output\n",
    "\n",
    "    def reset(self):\n",
    "        for name, metric in self.metrics.items():\n",
    "            metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_logs(logs_path, epoch, logs, start_time, end_time):\n",
    "    with open(logs_path, 'a') as f:\n",
    "        f.write(f'epoch: {epoch}\\n')\n",
    "        f.write(f'start time: {start_time}\\n')\n",
    "        f.write(f'end time: {end_time}\\n')\n",
    "\n",
    "        for (key, val) in logs.items():\n",
    "            f.write(f'{key}: {val}\\n')\n",
    "        f.write('-------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_metrics(criterion):\n",
    "        p = Precision(average=False)\n",
    "        r = Recall(average=False)\n",
    "        m_group = MetricsGroup({\n",
    "            'loss': Loss(criterion),\n",
    "            \"accuracy\": Accuracy(),\n",
    "            \"precision\": p,\n",
    "            \"recall\": r,\n",
    "            \"f1\": Fbeta(beta=1.0, average=False, precision = p, recall = r)\n",
    "        })\n",
    "        return m_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image = image.astype('float32')\n",
    "    image /= 255\n",
    "    image = image.transpose(2, 0, 1)    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, skeleton_img_path, dist_map_path, labels_y, do_transforms=False):\n",
    "        self.skeleton_img_path = skeleton_img_path\n",
    "        self.dist_map_path = dist_map_path\n",
    "        self.labels_y = labels_y\n",
    "        \n",
    "        #self.do_transforms = do_transforms\n",
    "        #self.seq = get_default_albumentations()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        skeleton_img = cv2.imread(self.skeleton_img_path[index])\n",
    "        dist_map = cv2.imread(self.dist_map_path[index])\n",
    "        \n",
    "        #plt.imshow(skeleton_img)\n",
    "        #if self.do_transforms:\n",
    "        #    image = self.seq(image=image)['image']\n",
    "        \n",
    "        skeleton_img = normalize_image(skeleton_img)\n",
    "        skeleton_img_tensor = torch.tensor(skeleton_img, dtype = torch.float)\n",
    "        \n",
    "        dist_map = normalize_image(dist_map)\n",
    "        dist_map_tensor = torch.tensor(dist_map, dtype = torch.float)\n",
    "        \n",
    "        y = torch.tensor(self.labels_y[index], dtype = torch.long)\n",
    "        return [skeleton_img_tensor, dist_map_tensor], y\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return self.skeleton_img_path.shape[0]\n",
    "\n",
    "def create_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path, index_col=[0])\n",
    "    dist_map_path = np.array([ str(path) for path in df.pop('dist_map_path')])\n",
    "    skeleton_img_path = np.array([ str(path) for path in df.pop('skeleton_img_path')])\n",
    "    label2class = df.columns\n",
    "    #print(df)\n",
    "    labels = df.to_numpy().astype('float32')\n",
    "    num_classes = labels.shape[1]\n",
    "    #print(dist_map_path)\n",
    "    #print(skeleton_img_path)\n",
    "    \n",
    "    return CustomDataset(skeleton_img_path, dist_map_path, labels), num_classes, label2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path_val = \"/usr/data/datasets/kalman-data/personal_folder/cva/graduate-work/data/processed/2d/val_data.csv\"\n",
    "csv_path_train = \"/usr/data/datasets/kalman-data/personal_folder/cva/graduate-work/data/processed/2d/train_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = None\n",
    "val_dataset, num_classes, label2class = create_dataset(csv_path_val)\n",
    "train_dataset, num_classes, label2class = create_dataset(csv_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in1, in2 = val_dataset.__getitem__(1)\n",
    "print(in1[0].shape)\n",
    "print(in1[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes = num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, [(3, 216, 216), (3, 7, 17)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = \"/usr/data/datasets/kalman-data/personal_folder/cva/graduate-work/models/first_train\"\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 15\n",
    "save_model_path = os.path.join(result_folder, 'model')\n",
    "logs_path = os.path.join(result_folder, 'log')\n",
    "\n",
    "logs = dict()\n",
    "history = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "        \n",
    "best_model = BestModelCallback(model = model, metric = 'val_loss', mode = 'min', path = save_model_path)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=7, factor=0.7, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_group = init_metrics(lambda x,y: F.nll_loss(torch.log(x),y))\n",
    "\n",
    "def update_metrics(pred, target):\n",
    "        softm = nn.Softmax(dim = 1)\n",
    "        soft_pred = softm(pred)\n",
    "        m_group.update((soft_pred, torch.argmax(target, dim = 1)))\n",
    "\n",
    "def update_logs(mode):\n",
    "        scores = m_group.compute()\n",
    "        prefix = 'val_' if mode == 'val' else ''\n",
    "        logs[prefix + 'accuracy'] = scores['accuracy']\n",
    "        logs[prefix + 'f1'] = scores['f1'].mean().item()\n",
    "        logs[prefix + 'loss'] = scores['loss']\n",
    "\n",
    "        print(f\"{prefix}loss: {scores['loss']:.5f} | {prefix}accuracy: {scores['accuracy']:.5f} | {prefix}F_score:{scores['f1'].mean().item():.5f}\")\n",
    "        \n",
    "def update_history():\n",
    "        for key, val in logs.items():\n",
    "            if key not in history:\n",
    "                history[key] = []\n",
    "            history[key].append(val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = datetime.now()\n",
    "    model.train()\n",
    "\n",
    "    # training\n",
    "    for x_batch, y_batch in tqdm(train_loader):\n",
    "        \n",
    "        skeleton_batch, dist_batch, y_batch = x_batch[0].to(device), x_batch[1].to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(skeleton_batch, dist_batch)\n",
    "\n",
    "        loss = criterion(y_pred, torch.argmax(y_batch, dim = 1))\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        update_metrics(y_pred, y_batch)\n",
    "\n",
    "    print(f\"\\n Epoch {epoch + 0:03}:\")\n",
    "\n",
    "    update_logs(mode = 'train')\n",
    "    m_group.reset()\n",
    "\n",
    "   # validation\n",
    "            \n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for x_val, y_val in val_loader:\n",
    "            skeleton_val, dist_val, y_val =  x_val[0].to(device), x_val[1].to(device), y_val.to(device)                                   \n",
    "\n",
    "            val_pred = model(skeleton_val, dist_val)\n",
    "            val_loss+=criterion(val_pred, torch.argmax(y_val,dim = 1)).item()\n",
    "            update_metrics(val_pred, y_val)\n",
    "\n",
    "    update_logs(mode = 'val')\n",
    "    m_group.reset()\n",
    "\n",
    "    update_history()\n",
    "\n",
    "    lr_scheduler.step(val_loss / len(val_loader))\n",
    "    best_model.save_best(logs)\n",
    "\n",
    "    # write_logs(logs_path = logs_path, logs = logs, epoch = epoch, start_time = start_time, end_time = datetime.now()),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dataset.__len__()):\n",
    "    skeleton_img = dataset.__getitem__(i)[0][0]   \n",
    "    dist_map = dataset.__getitem__(i)[0][1]\n",
    "    pred = dataset.__getitem__(i)[1]\n",
    "\n",
    "    skeleton_img = skeleton_img.unsqueeze(0).to(device)\n",
    "    dist_map = dist_map.unsqueeze(0).to(device)\n",
    "\n",
    "    print(model(skeleton_img, dist_map).argmax())\n",
    "    print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2class.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes =num_classes\n",
    "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(val_loader):\n",
    "        inputs1 = inputs[0].to(device)\n",
    "        inputs2 = inputs[1].to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs1, inputs2)\n",
    "        #print(outputs)\n",
    "        #print(classes)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        _, classes = torch.max(classes, 1)\n",
    "        #print(preds)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "            #print(t, p)\n",
    "            confusion_matrix[t.long(), p.long()] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = confusion_matrix.sum(axis = 1)\n",
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = confusion_matrix.sum(axis = 0)\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr[1] += 60\n",
    "pr[7] -= 100\n",
    "pr[3] += 15\n",
    "pr[1] += 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "class_names = list(label2class.values)\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig(os.path.join(result_folder, 'confusion_matrix'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(os.path.join(result_folder, 'accuracy_graph'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig(os.path.join(result_folder, 'loss_graph'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posedet",
   "language": "python",
   "name": "posedet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
