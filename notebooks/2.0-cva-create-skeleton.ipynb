{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "\n",
    "print('torch version:', torch.__version__, torch.cuda.is_available())\n",
    "print('torchvision version:', torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check MMPose installation\n",
    "import mmpose\n",
    "\n",
    "print('mmpose version:', mmpose.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "\n",
    "print('cuda version:', get_compiling_cuda_version())\n",
    "print('compiler information:', get_compiler_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mmpose.apis import (inference_top_down_pose_model, init_pose_model,\n",
    "                         vis_pose_result, process_mmdet_results)\n",
    "from mmdet.apis import inference_detector, init_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import tempfile\n",
    "import os.path as osp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pose_model, img, person_results, cnt):\n",
    "    # inference pose\n",
    "    pose_results, returned_outputs = inference_top_down_pose_model(\n",
    "        pose_model,\n",
    "        img,\n",
    "        person_results,\n",
    "        format='xyxy',\n",
    "        dataset=pose_model.cfg.data.test.type)  \n",
    "    # show pose estimation results\n",
    "    vis_result = mmpose.apis.vis_pose_tracking_result(\n",
    "        pose_model,\n",
    "        img,\n",
    "        pose_results,\n",
    "        show=False,\n",
    "        dataset=pose_model.cfg.data.test.type)\n",
    "        \n",
    "    vis_result = cv2.resize(vis_result, dsize=None, fx=0.5, fy=0.5)\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        file_name = osp.join(\"test\", f'pose_results_{cnt}.png')\n",
    "        cv2.imwrite(file_name, vis_result)\n",
    "        display(Image(file_name))\n",
    "    return pose_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pose model\n",
    "pose_config = '../source/mmpose/configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w48_coco_256x192.py'\n",
    "pose_checkpoint = 'https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth'\n",
    "pose_model = init_pose_model(pose_config, pose_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = \"/usr/data/datasets/kalman-data/personal_folder/cva/graduate-work/data/raw/videos\"\n",
    "annotations = \"/usr/data/datasets/kalman-data/personal_folder/cva/graduate-work/data/raw/volleyball_tracking_annotation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"/usr/data/datasets/kalman-data/personal_folder/cva/graduate-work/data/interim/2d/mmpose-result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_num(path):\n",
    "    name = path.split(\"/\")[-1]\n",
    "    num = int(name.split(\".\")[0])\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [f.path for f in os.scandir(videos) if f.is_dir()]\n",
    "datasets = sorted(datasets, key = sort_by_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for pdataset in datasets:\n",
    "    ndataset = pdataset.split(\"/\")[-1]\n",
    "    print(f\"INFO: dataset {ndataset}\")\n",
    "    \n",
    "    examples = [f.path for f in os.scandir(pdataset) if f.is_dir()]\n",
    "    for pexample in tqdm(examples):\n",
    "        tracks = set()\n",
    "        frames_info = defaultdict(list)\n",
    "        action_info = defaultdict(str)\n",
    "        \n",
    "        # read exist markup\n",
    "        nexample = pexample.split(\"/\")[-1]\n",
    "        with open(f'{annotations}/{ndataset}/{nexample}/{nexample}.txt') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                data = line.split()\n",
    "                id, xmin, ymin, xmax, ymax, frame, lost, grouping, generated = map(int, data[:-1])\n",
    "                action = str(data[-1])\n",
    "                action_info[id] = action\n",
    "                tracks.add(id)\n",
    "                if lost == 0:\n",
    "                    frames_info[frame].append({'bbox': np.array([xmin, ymin, xmax, ymax]), 'track_id':id})\n",
    "        # predict pose for each images, which have markup\n",
    "        images = sorted(glob(f\"{pexample}/*.*\"), key = sort_by_num)\n",
    "        pose_collection = defaultdict(dict)    \n",
    "        for img in images:\n",
    "            num = int(img.split(\"/\")[-1].split(\".\")[0])\n",
    "            for track_id in tracks:\n",
    "                 pose_collection[track_id][num] = None\n",
    "            if frames_info[num]:\n",
    "                cnt+=1\n",
    "                pose_results = predict(pose_model, img, frames_info[num], cnt)\n",
    "                for pose in pose_results:\n",
    "                    pose_collection[pose[\"track_id\"]][num] = pose[\"keypoints\"].tolist()\n",
    "        break\n",
    "        # write result for each person\n",
    "        result_dir = f\"{save_directory}/{ndataset}/{nexample}\"\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.makedirs(result_dir)\n",
    "        \n",
    "        for track_id in pose_collection:\n",
    "            result = {\n",
    "                \"action\": action_info[track_id],\n",
    "                \"pose\": pose_collection[track_id]\n",
    "            }\n",
    "            with open(f'{result_dir}/{track_id}.json', 'w+') as f:\n",
    "                json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_im_skeleton(skeleton, ax, color):    \n",
    "    bone_list = [[15, 13], [13, 11], [16, 14], [14, 12], [11, 12],\n",
    "                 [5, 11], [6, 12], [5, 6], [5, 7], [6, 8], [7, 9],\n",
    "                 [8, 10], [1, 2], [0, 1], [0, 2], [1, 3], [2, 4],\n",
    "                 [3, 5], [4, 6]]   \n",
    "    x = skeleton[:, 0]\n",
    "    y = skeleton[:, 1]\n",
    "    for bone in bone_list:\n",
    "        ax.plot([x[bone[0]], x[bone[1]]], [y[bone[0]], y[bone[1]]], color = color[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(data):\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(3,3))\n",
    "    plt.gca().invert_yaxis()\n",
    "    # ax.set_axis_off()\n",
    "    colors = plt.get_cmap('hsv')(np.linspace(0.0, 1, len(data)))\n",
    "    for i, point in enumerate(data):\n",
    "        plot_im_skeleton(point, ax, colors[i])\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in pose_collection:\n",
    "    pose_collection[pid] = np.array(pose_collection[pid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_img(pose_collection[0][:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('posedet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "be76c2709397d9eafcc9a33f3b53b00dab8cfa4aa815f4184d7daf7fc3f01ced"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
